{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import matthews_corrcoef as matt\n",
    "from hyperopt import hp\n",
    "from hyperopt import tpe\n",
    "from hyperopt import Trials\n",
    "from hyperopt import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reading the data. Data has stock tickers in the first row and dates in the first column. Only trading days are used.\n",
    "\"\"\"\n",
    "df = pd.read_excel('C:/Users/FS_Askar_A/midcap.xlsx', index_col=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_returns(dtf, tick, lead=5, lags=[1,2,3,4,5,7,10,15,20,30,50], tr=0.025):\n",
    "    \"\"\"\n",
    "    Calculates forward and lagged returns for a stock. Also creates target column\n",
    "    for returns over some threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dtf - data with all stock returns\n",
    "    tick - ticker of stock \n",
    "    lead - forward return lead\n",
    "    lags - lagged returns\n",
    "    tr - threshold value for target variable\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame for one stock with its price, forward and lagged returns and target column.\n",
    "    \"\"\"\n",
    "    dtf = dtf[[tick]]\n",
    "    dtf['fwd'] = dtf[tick].shift(-lead) / dtf[tick]-1\n",
    "    for lag in lags:\n",
    "        name = 'ret'+str(lag)\n",
    "        dtf[name] = dtf[tick]/dtf[tick].shift(lag)-1\n",
    "    dtf['ycol'] = np.where(dtf['fwd'] >= tr, 1, 0)\n",
    "    return dtf.dropna()\n",
    "\n",
    "\n",
    "def my_tss(dtf, split, train_size=1000, test_size=100):\n",
    "    \"\"\"\n",
    "    My take on time series split. It separates dataframe into \"past\" and \n",
    "    \"future\" from a splitting point. Also removes extra columns. \n",
    "    \n",
    "    Parameters:\n",
    "    dtf - dataframe of a stock\n",
    "    split - splitting point in trading days\n",
    "    train_size=1000 - size of the training sample\n",
    "    test_size=100 - size of the testing sample\n",
    "    \n",
    "    Returns:\n",
    "    trainx - training features\n",
    "    trainy - training target column\n",
    "    testx - testing features\n",
    "    testy - testing target column\n",
    "    \n",
    "    Attention!\n",
    "    This function is not fool-proof - it doesn't check whether the size of \n",
    "    the train size is less than splitting point or if testing sample has\n",
    "    any values. This is done for speed purposes as it is called thousands of times.\n",
    "    \"\"\"\n",
    "    train_start = split - train_size\n",
    "    test_end = split + test_size\n",
    "    trainx = dtf.drop(columns=[dtf.columns[0], 'fwd', 'ycol']).iloc[train_start:split]\n",
    "    testx = dtf.drop(columns=[dtf.columns[0], 'fwd', 'ycol']).iloc[split:test_end]\n",
    "    trainy = dtf['ycol'].iloc[train_start:split]\n",
    "    testy = dtf['ycol'].iloc[split:test_end]\n",
    "    return trainx, testx, trainy, testy\n",
    "\n",
    "\n",
    "def integerize(d):\n",
    "    \"\"\"\n",
    "    Converts hyperparameter values into integers. This is a compensation of hyperopt's \n",
    "    problem where it feeds integer values in float form. I.e. 2.0 instead of 2.\n",
    "    \n",
    "    Parameters:\n",
    "    d - dictionary of hyperparameters\n",
    "    \n",
    "    Returns:\n",
    "    d - dictionary of hyperparameters with integers where required\n",
    "    \"\"\"\n",
    "    \n",
    "    int_params = [\n",
    "        'train_size',\n",
    "        'test_size',\n",
    "        'num_leaves',\n",
    "        'max_depth',\n",
    "        'n_estimators',\n",
    "        'min_child_samples',\n",
    "        'upto',\n",
    "        'ticks_to_use'\n",
    "    ]\n",
    "    \n",
    "    for k in d:\n",
    "        if k in int_params:\n",
    "            d[k] = int(d[k])\n",
    "            \n",
    "    return d\n",
    "\n",
    "\n",
    "def calc_ret(results):\n",
    "    \"\"\"\n",
    "    Calculation of return from predicted data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results - list of dataframes. Dataframes must have 'avg' column, which is the \n",
    "                average 5-day forward return for the day.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    ===negative=== return for the whole period, across all the dataframes. \n",
    "                Return is negative because hyperopt minimizes a function.\n",
    "    \"\"\"\n",
    "    \n",
    "    bigdf = pd.concat(results)\n",
    "    bigdf['avg'] = bigdf.mean(axis=1).fillna(0)+1\n",
    "    \n",
    "    lead = 5\n",
    "    portf = 100\n",
    "    subportf = [portf/lead for l in range(lead)]\n",
    "    x = 0\n",
    "    for day in bigdf['avg']:\n",
    "        subportf[x%5] = subportf[x%5]*day\n",
    "        x+=1\n",
    "        \n",
    "    return 1-np.sum(subportf)/portf\n",
    "\n",
    "\n",
    "def check_params(params, upto, stock_num=20):\n",
    "    \"\"\"\n",
    "    Predicts on out-of-sample and out-of-cross-validation data\n",
    "    using optimized hyperparameters. \n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    params - optimized hyperparameters\n",
    "    upto - maximum split point for cross-validations,\n",
    "            here it is incremented by 100 to not include the\n",
    "            last validation sample (100 points in size)\n",
    "            \n",
    "    Returns:\n",
    "    --------\n",
    "    dataframe with 'avg' column, which is the \n",
    "                average 5-day forward return for the day.\n",
    "    \"\"\"\n",
    "    params = integerize(params)\n",
    "    bigdf = pd.DataFrame()\n",
    "    \n",
    "    for tick in df.columns[:stock_num]:\n",
    "        \n",
    "        tempdf = tickers_dfs[tick][['fwd']]\n",
    "        trainx, testx, trainy, testy = my_tss(tickers_dfs[tick], upto+100, \n",
    "                                              train_size=params['train_size'])\n",
    "        \n",
    "        my_model = LGBMClassifier(num_leaves=params['num_leaves'],\n",
    "                                     max_depth=params['max_depth'],\n",
    "                                     learning_rate=params['learning_rate'],\n",
    "                                     n_estimators=params['n_estimators'],\n",
    "                                     min_child_samples=params['min_child_samples'])\n",
    "        \n",
    "        sw = np.where(trainy==0, params['sw'], 1)\n",
    "            \n",
    "        my_model.fit(trainx, trainy, sample_weight=sw)\n",
    "        \n",
    "        testx['pred'] = my_model.predict(testx)\n",
    "        tempdf['pred'] = testx['pred']\n",
    "        tempdf.dropna(inplace=True)\n",
    "        tempdf['predret'] = np.where(tempdf['pred']==1, tempdf['fwd'], np.nan)\n",
    "        bigdf[tick] = tempdf['predret']\n",
    "        \n",
    "    bigdf['avg'] = bigdf.mean(axis=1).fillna(0)+1\n",
    "        \n",
    "    return bigdf\n",
    "\n",
    "\n",
    "def check_paramsEF(tick_params, upto):\n",
    "    \"\"\"\n",
    "    Predicts on out-of-sample and out-of-cross-validation data\n",
    "    using optimized hyperparameters for every ticker separately. \n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    tick_params - dict of optimized hyperparameters\n",
    "    upto - maximum split point for cross-validations,\n",
    "            here it is incremented by 100 to not include the\n",
    "            last validation sample (100 points in size)\n",
    "            \n",
    "    Returns:\n",
    "    --------\n",
    "    dataframe with 'avg' column, which is the \n",
    "                average 5-day forward return for the day.\n",
    "    \"\"\"\n",
    "    \n",
    "    bigdf = pd.DataFrame()\n",
    "    \n",
    "    for tick, params in tick_params.items():\n",
    "        \n",
    "        params = integerize(params)\n",
    "        \n",
    "        tempdf = tickers_dfs[tick][['fwd']]\n",
    "        trainx, testx, trainy, testy = my_tss(tickers_dfs[tick], upto+100, \n",
    "                                              train_size=params['train_size'])\n",
    "        \n",
    "        my_model = LGBMClassifier(num_leaves=params['num_leaves'],\n",
    "                                     max_depth=params['max_depth'],\n",
    "                                     learning_rate=params['learning_rate'],\n",
    "                                     n_estimators=params['n_estimators'],\n",
    "                                     min_child_samples=params['min_child_samples'])\n",
    "        \n",
    "        sw = np.where(trainy==0, params['sw'], 1)\n",
    "\n",
    "        my_model.fit(trainx, trainy, sample_weight=sw)\n",
    "        \n",
    "        testx['pred'] = my_model.predict(testx)\n",
    "        tempdf['pred'] = testx['pred']\n",
    "        tempdf.dropna(inplace=True)\n",
    "        tempdf['predret'] = np.where(tempdf['pred']==1, tempdf['fwd'], np.nan)\n",
    "        bigdf[tick] = tempdf['predret']\n",
    "        \n",
    "    bigdf['avg'] = bigdf.mean(axis=1).fillna(0)+1\n",
    "        \n",
    "    return bigdf\n",
    "\n",
    "\n",
    "def get_est_series(dtf, com=0):\n",
    "    \"\"\"\n",
    "    Calculates total return over several out-of-cross-validation samples.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dtf - dataframe with 'avg' column\n",
    "    com=0 - value of commissions for ==one== side of a trade in USD/share\n",
    "    \n",
    "    Returns:\n",
    "    portf_series - series with portfolio value at a point in time\n",
    "    \"\"\"\n",
    "    \n",
    "    comdf = dtf.drop(columns=['avg'])\n",
    "    for tick in dtf.columns[:-1]:\n",
    "        if df[tick].iloc[1600] >= 0:\n",
    "            comdf[tick] = (df[tick].shift(-5)-com) / (df[tick]+com)-1\n",
    "            comdf[tick] = np.where(dtf[tick].notna(), comdf[tick], np.nan)\n",
    "        else:\n",
    "            comdf[tick] = np.nan\n",
    "    comdf['avg'] = comdf.mean(axis=1).fillna(0)+1\n",
    "    \n",
    "    portf_series = []\n",
    "    lead = 5\n",
    "    portf = 100\n",
    "    subportf = [portf/lead for l in range(lead)]\n",
    "    x = 0\n",
    "    for day in comdf['avg']:\n",
    "        subportf[x%5] = subportf[x%5]*day\n",
    "        portf_series.append(subportf.copy())\n",
    "        x+=1\n",
    "    \n",
    "    portf_series = pd.DataFrame(portf_series, index=comdf.index)\n",
    "    portf_series = portf_series.shift(5)\n",
    "    portf_series = portf_series.fillna(20).sum(axis=1)\n",
    "    \n",
    "    return portf_series\n",
    "\n",
    "\n",
    "def get_res(params):\n",
    "    \n",
    "    mymodel_results = []\n",
    "\n",
    "    for tick in df.columns:\n",
    "\n",
    "        for split in range(1000, 2200, 100):\n",
    "            trainx, testx, trainy, testy = my_tss(tickers_dfs[tick], split)\n",
    "            my_model = LGBMClassifier(**params)\n",
    "            my_model.fit(trainx, trainy)\n",
    "            predy = my_model.predict(testx)\n",
    "            mymodel_results.append(matt(testy, predy))\n",
    "\n",
    "    return np.mean(mymodel_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tickers_dfs = {}\n",
    "\n",
    "for tick in tqdm_notebook(df.columns):\n",
    "    tickers_dfs[tick] = create_returns(df, tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model A317 - all 317 stocks\n",
    "\"\"\"\n",
    "\n",
    "modelA317_results = {}\n",
    "\n",
    "for tick in tqdm_notebook(df.columns):\n",
    "    \n",
    "    tick_results = []\n",
    "    \n",
    "    for split in range(1000, 2200, 100):\n",
    "        trainx, testx, trainy, testy = my_tss(tickers_dfs[tick], split)\n",
    "        my_model = LGBMClassifier()\n",
    "        my_model.fit(trainx, trainy)\n",
    "        predy = my_model.predict(testx)\n",
    "        tick_results.append(matt(testy, predy))\n",
    "    \n",
    "    modelA317_results[tick] = np.mean(tick_results)\n",
    "\n",
    "modelA317_results = pd.Series(modelA317_results)    \n",
    "\n",
    "print(\"Average matt score across all stocks:\", round(modelA317_results.mean(), 3))\n",
    "print(\"Min matt score across all stocks:\", round(modelA317_results.min(), 3))\n",
    "print(\"Max matt score across all stocks:\", round(modelA317_results.max(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model A20 - first 20 stocks\n",
    "\"\"\"\n",
    "\n",
    "modelA20_results = {}\n",
    "\n",
    "for tick in tqdm_notebook(df.columns[:20]):\n",
    "    \n",
    "    tick_results = []\n",
    "    \n",
    "    for split in range(1000, 2200, 100):\n",
    "        trainx, testx, trainy, testy = my_tss(tickers_dfs[tick], split)\n",
    "        my_model = LGBMClassifier()\n",
    "        my_model.fit(trainx, trainy)\n",
    "        predy = my_model.predict(testx)\n",
    "        tick_results.append(matt(testy, predy))\n",
    "    \n",
    "    modelA20_results[tick] = np.mean(tick_results)\n",
    "\n",
    "modelA20_results = pd.Series(modelA20_results)    \n",
    "\n",
    "print(\"Average matt score for the first 20 stocks:\", round(modelA20_results.mean(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_changes = {\n",
    "    'num_leaves': 4,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators': 20,\n",
    "    'min_child_samples': 10\n",
    "}\n",
    "\n",
    "for k, v in params_changes.items():\n",
    "    print(\"Parameter\", k, \"changed value to\", v, \\\n",
    "          \"Average matt score changed to\", round(get_res({k: v}), 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
